{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560902cd",
   "metadata": {},
   "source": [
    "# Loading Data to VM and setting up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eef0794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MIDIs: 116189\n",
      "Here are three examples: [PosixPath('data/lmd_matched/A/A/A/TRAAAGR128F425B14B/1d9d16a9da90c090809c153754823c2b.mid'), PosixPath('data/lmd_matched/A/A/A/TRAAAGR128F425B14B/5dd29e99ed7bd3cc0c5177a6e9de22ea.mid'), PosixPath('data/lmd_matched/A/A/A/TRAAAGR128F425B14B/b97c529ab9ef783a849b896816001748.mid')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, tqdm, json, os, math\n",
    "\n",
    "ROOT = Path(\"data/lmd_matched\").expanduser()\n",
    "midi_files = sorted(ROOT.rglob(\"*.mid\")) + sorted(ROOT.rglob(\"*.midi\"))\n",
    "print(\"Number of MIDIs:\", len(midi_files))\n",
    "print(\"Here are three examples:\", midi_files[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2f2a6",
   "metadata": {},
   "source": [
    "# Basic integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c9ccc",
   "metadata": {},
   "source": [
    "## A glimpse into the type of music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b08383",
   "metadata": {},
   "source": [
    "the following graph tells us how the models are going to behave according to the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f3f80f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/term_distro.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m terms_distro = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/term_distro.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m mbtags_distro = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/mbtag_distro.csv\u001b[39m\u001b[33m\"\u001b[39m, delimiter=\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m fig, (ax1, ax2) = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m16\u001b[39m, \u001b[32m7\u001b[39m), tight_layout=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/bachelor_thesis/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/bachelor_thesis/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/bachelor_thesis/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/bachelor_thesis/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/bachelor_thesis/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/term_distro.csv'"
     ]
    }
   ],
   "source": [
    "terms_distro = pd.read_csv(\"data/term_distro.csv\", delimiter=\",\")\n",
    "mbtags_distro = pd.read_csv(\"data/mbtag_distro.csv\", delimiter=\",\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7), tight_layout=True)\n",
    "\n",
    "ax1.bar(terms_distro[\"genre_term\"].loc[:20], terms_distro[\"n_tracks\"].loc[:20])\n",
    "ax1.set_title(\"Distribution of genre terms\", fontweight=\"bold\")\n",
    "ax1.set_ylabel(\"Number of tracks\")\n",
    "ax1.set_xlabel(\"Genre term\")\n",
    "ax1.tick_params(axis=\"x\", labelrotation=45)\n",
    "for t in ax1.get_xticklabels():\n",
    "    t.set_ha(\"right\")\n",
    "\n",
    "ax2.bar(mbtags_distro[\"genre_tag\"].loc[:20], mbtags_distro[\"n_tracks\"].loc[:20])\n",
    "ax2.set_title(\"Distribution of musicbrainz tags\", fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Number of tracks\")\n",
    "ax2.set_xlabel(\"Genre tag\")\n",
    "ax2.tick_params(axis=\"x\", labelrotation=45)\n",
    "for t in ax2.get_xticklabels():\n",
    "    t.set_ha(\"right\")\n",
    "plt.savefig(\"data_reports/genre_distribution.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e80e3b",
   "metadata": {},
   "source": [
    "## Some statistics on a sample from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi, random, statistics\n",
    "from tqdm import tqdm\n",
    "\n",
    "rng = random.Random()\n",
    "sample = rng.sample(midi_files, k=5000)\n",
    "\n",
    "\n",
    "def safe_read(p):\n",
    "    try:\n",
    "        pm = pretty_midi.PrettyMIDI(str(p))\n",
    "        return pm\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "rows = []\n",
    "for p in tqdm(sample):\n",
    "    pm = safe_read(p)\n",
    "    ok = pm is not None\n",
    "    dur = pm.get_end_time() if ok else np.nan\n",
    "    tempos = [] if not ok else [t for t in pm.get_tempo_changes()[1]]\n",
    "    time_sigs = (\n",
    "        []\n",
    "        if not ok\n",
    "        else [(ts.numerator, ts.denominator) for ts in pm.time_signature_changes]\n",
    "    )\n",
    "    n_notes = 0 if not ok else sum(len(i.notes) for i in pm.instruments)\n",
    "    n_instr = 0 if not ok else len(set([i.program for i in pm.instruments]))\n",
    "    rows.append(\n",
    "        dict(\n",
    "            path=str(p),\n",
    "            ok=ok,\n",
    "            duration=dur,\n",
    "            notes=n_notes,\n",
    "            instruments=n_instr,\n",
    "            tempi=len(tempos),\n",
    "            time_sigs=len(time_sigs),\n",
    "        )\n",
    "    )\n",
    "df_basic = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(df_basic, title=\"Data Report\", explorative=True)\n",
    "profile.to_notebook_iframe() # open in your browser\n",
    "profile.to_file(\"data_reports/basic_info.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed45cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "prog_ctr, drum_ctr = Counter(), 0\n",
    "#poly_vals, dens_vals, pitch_min, pitch_max = [], [], [], []\n",
    "for p in tqdm(sample):\n",
    "    pm = safe_read(p)\n",
    "    if not pm: continue\n",
    "    active_times = []\n",
    "    for inst in pm.instruments:\n",
    "        if inst.is_drum:\n",
    "            drum_ctr += 1\n",
    "        else:\n",
    "            prog_ctr[inst.program] += 1\n",
    "        for n in inst.notes:\n",
    "            active_times.append((n.start, +1))\n",
    "            active_times.append((n.end, -1))\n",
    "            pitch_min.append(n.pitch); pitch_max.append(n.pitch)\n",
    "    # crude polyphony estimate\n",
    "    active_times.sort()\n",
    "    cur, max_poly = 0, 0\n",
    "    for t, d in active_times:\n",
    "        cur += d\n",
    "        max_poly = max(max_poly, cur)\n",
    "    poly_vals.append(max_poly)\n",
    "    dur = pm.get_end_time() or 1e-6\n",
    "    total_notes = sum(len(i.notes) for i in pm.instruments)\n",
    "    dens_vals.append(total_notes / max(dur, 1e-6))\n",
    "\n",
    "pd.Series(poly_vals).hist(bins=50); plt.title(\"Max polyphony (sample)\"); plt.show()\n",
    "pd.Series(dens_vals).hist(bins=50); plt.title(\"Note density (notes/sec)\"); plt.show()\n",
    "pd.Series(pitch_min+pitch_max).describe(), prog_ctr.most_common(10), drum_ctr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64315cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import muspy\n",
    "\n",
    "prog_ctr, drum_ctr = Counter(), 0\n",
    "pitch_min, pitch_max = [], []\n",
    "rows = []\n",
    "for p in tqdm(sample):\n",
    "    pm = safe_read(p)\n",
    "    if not pm:\n",
    "        continue\n",
    "\n",
    "    # --- per-instrument bookkeeping ---\n",
    "    for inst in pm.instruments:\n",
    "        if inst.is_drum:\n",
    "            drum_ctr += 1\n",
    "        else:\n",
    "            prog_ctr[inst.program] += 1\n",
    "        for n in inst.notes:\n",
    "            pitch_min.append(n.pitch)\n",
    "            pitch_max.append(n.pitch)\n",
    "\n",
    "    m = muspy.from_pretty_midi(pm)\n",
    "    ts = m.time_signatures[0] if m.time_signatures else muspy.TimeSignature(4, 4, 0)\n",
    "    def safe_measure_resolution(m):\n",
    "        # pick the first time signature with a valid, nonzero denominator\n",
    "        ts = next((ts for ts in m.time_signatures if getattr(ts, \"denominator\", 0) > 0), None)\n",
    "        if ts is None:\n",
    "            num, den = 4, 4          # fallback if none/invalid\n",
    "        else:\n",
    "            num, den = ts.numerator, ts.denominator\n",
    "            # MIDI TS denominators should be powers of two; sanitize if needed\n",
    "            if den <= 0:\n",
    "                den = 4\n",
    "        # use float division then round to keep intent even if den not dividing evenly\n",
    "        return int(round(m.resolution * num * 4 / den))\n",
    "\n",
    "    measure_resolution = safe_measure_resolution(m)\n",
    "\n",
    "    # --- note-density calculation ---\n",
    "    dur = pm.get_end_time() or 1e-6\n",
    "    total_notes = sum(len(i.notes) for i in pm.instruments)\n",
    "\n",
    "    beat = m.resolution\n",
    "    grid16 = max(beat // 4, 1)\n",
    "\n",
    "    total_notes = sum(len(t.notes) for t in m.tracks)\n",
    "    non_drum_notes = [n for t in m.tracks if not t.is_drum for n in t.notes]\n",
    "    drum_notes = [n for t in m.tracks if t.is_drum for n in t.notes]\n",
    "\n",
    "    # A) validity & hygiene\n",
    "    def overlaps_same_pitch(track):\n",
    "        by_pitch = {}\n",
    "        bad = 0\n",
    "        notes = sorted(track.notes, key=lambda x: (x.pitch, x.time, x.end))\n",
    "        for n in notes:\n",
    "            by_pitch.setdefault(n.pitch, []).append((n.time, n.end))\n",
    "        for spans in by_pitch.values():\n",
    "            last_end = -1\n",
    "            for t0, t1 in spans:\n",
    "                if t0 < last_end:\n",
    "                    bad += 1\n",
    "                last_end = max(last_end, t1)\n",
    "        return bad\n",
    "\n",
    "    same_pitch_overlap_count = sum(\n",
    "        overlaps_same_pitch(t) for t in m.tracks if not t.is_drum\n",
    "    )\n",
    "    ts_changes = max(len(m.time_signatures) - 1, 0)\n",
    "    parsable_nonempty = int(total_notes > 0 and dur > 0)\n",
    "\n",
    "    # B) rhythm & timing\n",
    "    bpms = [tm.qpm for tm in m.tempos]\n",
    "    tempo_mean_bpm = (sum(bpms) / len(bpms)) if bpms else float(\"nan\")\n",
    "    tempo_std_bpm = (\n",
    "        ((sum((x - tempo_mean_bpm) ** 2 for x in bpms) / len(bpms)) ** 0.5)\n",
    "        if len(bpms) > 1\n",
    "        else 0.0\n",
    "    )\n",
    "    tempo_changes = max(len(bpms) - 1, 0)\n",
    "\n",
    "    off = sum((n.time % grid16) != 0 for t in m.tracks for n in t.notes)\n",
    "    offgrid_rate_16 = off / max(total_notes, 1)\n",
    "\n",
    "    # measure counts for density variance and length\n",
    "    length = max((t.get_end_time() for t in m.tracks), default=0)\n",
    "    n_measures = int(length // measure_resolution) + 1 if length > 0 else 0\n",
    "    counts_per_measure = [\n",
    "        sum(1 for t in m.tracks for n in t.notes if (n.time // measure_resolution) == k)\n",
    "        for k in range(n_measures)\n",
    "    ]\n",
    "    if counts_per_measure:\n",
    "        mean_c = sum(counts_per_measure) / len(counts_per_measure)\n",
    "        onset_density_var_meas = sum(\n",
    "            (c - mean_c) ** 2 for c in counts_per_measure\n",
    "        ) / len(counts_per_measure)\n",
    "    else:\n",
    "        onset_density_var_meas = float(\"nan\")\n",
    "\n",
    "    # C) dynamics & articulation\n",
    "    vels = [n.velocity for n in non_drum_notes]\n",
    "    if vels:\n",
    "        v_mean = sum(vels) / len(vels)\n",
    "        velocity_mean = v_mean\n",
    "        velocity_std = (sum((v - v_mean) ** 2 for v in vels) / len(vels)) ** 0.5\n",
    "        sv = sorted(vels)\n",
    "        p5 = sv[int(0.05 * len(sv))]\n",
    "        p95 = sv[max(int(0.95 * len(sv)) - 1, 0)]\n",
    "        velocity_p95_minus_p5 = p95 - p5\n",
    "    else:\n",
    "        velocity_mean = velocity_std = velocity_p95_minus_p5 = float(\"nan\")\n",
    "\n",
    "    articulation_ratio = (\n",
    "        (\n",
    "            sum(n.duration for t in m.tracks for n in t.notes)\n",
    "            / max(total_notes * beat, 1)\n",
    "        )\n",
    "        if total_notes\n",
    "        else float(\"nan\")\n",
    "    )\n",
    "\n",
    "    # D) instrumentation & meta\n",
    "    track_count = len(m.tracks)\n",
    "    drum_note_ratio = len(drum_notes) / max(total_notes, 1)\n",
    "    pitch_register_mean = (\n",
    "        (sum(n.pitch for n in non_drum_notes) / len(non_drum_notes))\n",
    "        if non_drum_notes\n",
    "        else float(\"nan\")\n",
    "    )\n",
    "    length_measures = n_measures\n",
    "\n",
    "    rows.append(\n",
    "        dict(\n",
    "            path=str(p),\n",
    "            polyphony=muspy.metrics.polyphony(m),\n",
    "            polyphony_rate=muspy.metrics.polyphony_rate(m),\n",
    "            notes_density=total_notes / max(dur, 1e-6),\n",
    "            empty_beat_rate=muspy.metrics.empty_beat_rate(m),\n",
    "            empty_measure_rate=muspy.metrics.empty_measure_rate(m, measure_resolution),\n",
    "            groove_consistency=muspy.metrics.groove_consistency(m, measure_resolution),\n",
    "            n_pitch_classes_used=muspy.metrics.n_pitch_classes_used(m),\n",
    "            n_pitches_used=muspy.metrics.n_pitches_used(m),\n",
    "            pitch_class_entropy=muspy.metrics.pitch_class_entropy(m),\n",
    "            pitch_entropy=muspy.metrics.pitch_entropy(m),\n",
    "            pitch_range=muspy.metrics.pitch_range(m),\n",
    "            scale_consistency=muspy.metrics.scale_consistency(m),\n",
    "            same_pitch_overlap_count=same_pitch_overlap_count,\n",
    "            time_signature_changes=ts_changes,\n",
    "            parsable_nonempty=parsable_nonempty,\n",
    "            tempo_mean_bpm=tempo_mean_bpm,\n",
    "            tempo_std_bpm=tempo_std_bpm,\n",
    "            tempo_changes=tempo_changes,\n",
    "            offgrid_rate_16=offgrid_rate_16,\n",
    "            onset_density_var_meas=onset_density_var_meas,\n",
    "            velocity_mean=velocity_mean,\n",
    "            velocity_std=velocity_std,\n",
    "            velocity_p95_minus_p5=velocity_p95_minus_p5,\n",
    "            articulation_ratio=articulation_ratio,\n",
    "            drum_note_ratio=drum_note_ratio,\n",
    "            pitch_register_mean=pitch_register_mean,\n",
    "            length_measures=length_measures,\n",
    "        )\n",
    "    )\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "pd.Series(pitch_min + pitch_max).describe(), prog_ctr.most_common(10), drum_ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df_metrics, title=\"Metrics Report\", explorative=True)\n",
    "profile.to_notebook_iframe() # open in your browser\n",
    "profile.to_file(\"data_reports/metrics.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c946e8e",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5fb004",
   "metadata": {},
   "source": [
    "### 🔥 Strongest Correlations\n",
    "\n",
    "#### Near-duplicates\n",
    "- **Tempo-related**\n",
    "  - `tempo_changes ↔ tempo_std_bpm` **0.954**  \n",
    "    More tempo changes → higher tempo variability.\n",
    "- **Dynamics-related**\n",
    "  - `velocity_p95_minus_p5 ↔ velocity_std` **0.951**  \n",
    "    Both measure spread of dynamics.\n",
    "- **Sparsity-related**\n",
    "  - `empty_beat_rate ↔ empty_measure_rate` **0.863**  \n",
    "    Sparse beats go with sparse measures.\n",
    "- **Pitch/tonal clarity**\n",
    "  - `pitch_class_entropy ↔ scale_consistency` **−0.848**  \n",
    "    More tonal ambiguity → less scale consistency.\n",
    "- **Pitch diversity**\n",
    "  - `n_pitches_used ↔ pitch_entropy` **0.798**  \n",
    "    More unique pitches → higher pitch entropy.\n",
    "- **Texture**\n",
    "  - `polyphony ↔ polyphony_rate` **0.790**  \n",
    "    Essentially the same concept.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎵 Pitch & Harmony Cluster\n",
    "- `n_pitch_classes_used ↔ n_pitches_used` **0.764**\n",
    "- `pitch_class_entropy ↔ pitch_entropy` **0.759**\n",
    "- `n_pitch_classes_used ↔ pitch_class_entropy` **0.693**\n",
    "- `n_pitches_used ↔ pitch_class_entropy` **0.692**\n",
    "- `n_pitches_used ↔ scale_consistency` **−0.650**\n",
    "- `n_pitches_used ↔ pitch_range` **0.638**\n",
    "- `pitch_entropy ↔ scale_consistency` **−0.635**\n",
    "\n",
    "**Interpretation:**  \n",
    "Greater pitch variety leads to higher entropy, wider pitch range, and weaker adherence to a single scale.\n",
    "\n",
    "---\n",
    "\n",
    "### 🥁 Rhythm & Tightness\n",
    "- `groove_consistency ↔ offgrid_rate_16` **−0.721**  \n",
    "  More off-grid 16ths → lower groove consistency.\n",
    "- `notes_density ↔ onset_density_var_meas` **0.622**  \n",
    "  Denser textures → greater onset variance.\n",
    "- `articulation_ratio ↔ notes_density` **−0.527**  \n",
    "  Dense notes → shorter articulations.\n",
    "\n",
    "---\n",
    "\n",
    "### ⏱️ Tempo & Length\n",
    "- `length_measures ↔ tempo_mean_bpm` **0.536**  \n",
    "  Longer pieces → higher mean BPM (dataset-specific effect).\n",
    "- `notes_density ↔ tempo_mean_bpm` **0.442**  \n",
    "  Faster tempos → denser textures.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎼 Polyphony & Articulation\n",
    "- `articulation_ratio ↔ polyphony_rate` **0.506**\n",
    "- `articulation_ratio ↔ polyphony` **0.425**  \n",
    "\n",
    "**Interpretation:**  \n",
    "Higher note overlap (polyphony) is associated with longer articulations.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Practical Takeaways\n",
    "\n",
    "#### Feature Selection\n",
    "To reduce **multicollinearity**, drop one from each of these pairs:\n",
    "- `tempo_changes` vs. `tempo_std_bpm`\n",
    "- `velocity_p95_minus_p5` vs. `velocity_std`\n",
    "- `empty_beat_rate` vs. `empty_measure_rate`\n",
    "- `polyphony` vs. `polyphony_rate`\n",
    "- Among pitch/tonal measures, keep a compact subset (e.g., `n_pitch_classes_used`, `scale_consistency`, `pitch_entropy`).\n",
    "\n",
    "#### Latent Factors (useful for PCA or clustering)\n",
    "- **Tonal variety / ambiguity:** (`pitch_entropy`, `pitch_class_entropy`, `n_pitches_used`, inverse of `scale_consistency`)\n",
    "- **Rhythmic tightness vs looseness:** (`groove_consistency` vs. `offgrid_rate_16`)\n",
    "- **Density / energy:** (`notes_density`, `onset_density_var_meas`, `tempo_mean_bpm`)\n",
    "- **Dynamics spread:** (`velocity_std` or `velocity_p95_minus_p5`)\n",
    "- **Texture:** (`polyphony`, `polyphony_rate`, linked to `articulation_ratio`)\n",
    "\n",
    "#### Sanity Check\n",
    "- Off-grid timing decreases groove consistency (expected).\n",
    "- More pitch classes reduce tonal stability (expected).\n",
    "- Denser passages encourage staccato articulation (musically intuitive).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05876038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
