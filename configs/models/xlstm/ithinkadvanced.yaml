vocab_size: 2048         
context_length: 1024
embedding_dim: 512
num_blocks: 12
dropout: 0.1
slstm_at: [1,3,5,7,9,11]
mlstm_block:
  mlstm:
    conv1d_kernel_size: 4
    qkv_proj_blocksize: 4
    num_heads: 8
slstm_block:
  slstm:
    backend: cuda
    num_heads: 8
    conv1d_kernel_size: 4
    bias_init: powerlaw_blockdependent
  feedforward:
    proj_factor: 1.3
    act_fn: gelu
